---
layout: post
comments: true
title: Transferable Visual Models with NLP Supervision
author: Michael Simon, Victor Lin
date: 2022-02-26
---


> The creation of high quality labeled datasets for the purposes of training Computer Vision models remains one of the most time consuming tasks for Computer Vision research. Consequently, alternative methods of extracting label information from existing images and visual data is one of the areas of focus for recent research. In this blog we explore one of these state of the art methods in training Image Classification models, CLIP (Contrastive Language–Image Pre-training). Extracting latent labels from images already associated with text widely available on the internet is a promising method to fast-track the training of Computer Vision models using text *and* image encoders.


- [Introduction](#introduction)
- [Alternative Methods of Supervision](#alternative-methods-of-supervision)
- [CLIP](#clip)
- [Relevant Research Papers](#relevant-research-papers)
- [References](#references)


## Introduction



## Alternative Methods of Supervision



## CLIP



## Relevant Research Papers

**Learning Transferable Visual Models From Natural Language Supervision**

Proposes a novel method of training image classification models via latent label extraction with text encoders [1]

Website article: https://openai.com/blog/clip/

Paper: https://arxiv.org/abs/2103.00020


**PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows**

Proposes a novel method of generating 3D point clouds via a probabilistic framework to that models them as a distribution of distributions. [2]

Website article: https://www.guandaoyang.com/PointFlow/

Paper: https://arxiv.org/abs/1906.12320

**Learning Gradient Fields for Shape Generation**

Proposes a method for 3D point cloud generation using stochastic gradient ascent on an unnormalized probability density, which moves the sampled points in the direction of high-likelihood regions. [3]

Website article: https://www.cs.cornell.edu/~ruojin/ShapeGF/

Paper: https://arxiv.org/abs/2008.06520

## References

[1] Radford, Alec, et al. "Learning transferable visual models from natural language supervision." International conference on machine learning. PMLR, 2021.

[2] 

[3] 

OLD: 

[1] Zhou, Linqi et al. "3D Shape Generation and Completion Through Point-Voxel Diffusion." *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV).* 2021.

[2] Yang, Guandao et al. "PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows." (2019).

[3] Cai, R. et al. “Learning gradient fields for shape generation,” *Computer Vision – ECCV* (2020: pp. 364–381.