{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DianaDai426/CS188-Projects-2023Winter/blob/main/CLIP-experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUBLS1d2CJZp"
      },
      "source": [
        "# `clip_retrieval.clip_client`\n",
        "\n",
        "This python module allows you to query a backend remote via its exposed REST api."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT9FwUjk_lRD"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lBX_J9ZeCJZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb1ec9a-dc15-41b7-e0aa-c8b8c494306f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clip-retrieval\n",
            "  Downloading clip_retrieval-2.36.1-py3-none-any.whl (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.2/353.2 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting img2dataset\n",
            "  Downloading img2dataset-1.41.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 KB\u001b[0m \u001b[31m655.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (1.22.4)\n",
            "Collecting faiss-cpu<2,>=1.7.2\n",
            "  Downloading faiss_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow<8,>=6.0.1\n",
            "  Downloading pyarrow-7.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clip-anytorch<3,>=2.5.0\n",
            "  Downloading clip_anytorch-2.5.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2,>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (1.3.5)\n",
            "Requirement already satisfied: tqdm<5,>=4.62.3 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (4.64.1)\n",
            "Collecting flask-cors<4,>=3.0.10\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.1 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (3.8.4)\n",
            "Collecting wandb<0.13,>=0.12.10\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers<3,>=2.2.0\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py<4,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (3.1.0)\n",
            "Requirement already satisfied: torch<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (1.13.1+cu116)\n",
            "Collecting flask-restful<1,>=0.3.9\n",
            "  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
            "Collecting flask<3,>=2.0.3\n",
            "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webdataset<0.3,>=0.2\n",
            "  Downloading webdataset-0.2.33-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multilingual-clip<2,>=1.0.10\n",
            "  Downloading multilingual_clip-1.0.10-py3-none-any.whl (20 kB)\n",
            "Collecting requests<3,>=2.27.1\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire<0.5.0,>=0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fsspec==2022.11.0\n",
            "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting open-clip-torch<3.0.0,>=2.0.0\n",
            "  Downloading open_clip_torch-2.15.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autofaiss<3,>=2.9.6\n",
            "  Downloading autofaiss-2.15.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision<2,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (0.14.1+cu116)\n",
            "Requirement already satisfied: prometheus-client<1,>=0.13.1 in /usr/local/lib/python3.8/dist-packages (from clip-retrieval) (0.16.0)\n",
            "Collecting dataclasses<1.0.0,>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: albumentations<2,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from img2dataset) (1.2.1)\n",
            "Requirement already satisfied: opencv-python-headless<5,>=4.5.5.62 in /usr/local/lib/python3.8/dist-packages (from img2dataset) (4.7.0.68)\n",
            "Collecting exifread-nocycle<4,>=3.0.1\n",
            "  Downloading ExifRead_nocycle-3.0.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (3.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (4.0.2)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (0.0.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (6.0)\n",
            "Collecting embedding-reader<2,>=1.2.0\n",
            "  Downloading embedding_reader-1.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from clip-anytorch<3,>=2.5.0->clip-retrieval) (2022.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire<0.5.0,>=0.4.0->clip-retrieval) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire<0.5.0,>=0.4.0->clip-retrieval) (2.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from flask<3,>=2.0.3->clip-retrieval) (6.0.0)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting click>=8.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Werkzeug>=2.2.2\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from flask-restful<1,>=0.3.9->clip-retrieval) (2022.7.1)\n",
            "Collecting aniso8601>=0.82\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.20.*\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2,>=1.1.5->clip-retrieval) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (2.10)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3,>=2.2.0->clip-retrieval) (1.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3,>=2.2.0->clip-retrieval) (3.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2,>=1.7.1->clip-retrieval) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision<2,>=0.10.1->clip-retrieval) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.13,>=0.12.10->clip-retrieval) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb<0.13,>=0.12.10->clip-retrieval) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb<0.13,>=0.12.10->clip-retrieval) (5.4.8)\n",
            "Collecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->clip-retrieval) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->clip-retrieval) (3.9.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->flask<3,>=2.0.3->clip-retrieval) (3.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->flask<3,>=2.0.3->clip-retrieval) (2.0.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (3.5.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (2023.2.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers<3,>=2.2.0->clip-retrieval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers<3,>=2.2.0->clip-retrieval) (3.1.0)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy->clip-anytorch<3,>=2.5.0->clip-retrieval) (0.2.6)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (3.0.9)\n",
            "Building wheels for collected packages: fire, sentence-transformers, pathtools\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=bb59d441b681f32337324fecab1da4a5a3d14ac2224903988cbf994ad9d978b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=7a3f9adaac08f5cbc4769bc88e06f0cf10c6dc07cd94cdf32eb0750da0dc40b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=d770a53095574a1074cc588b95e3812c0150ce242b77eb7fb884a47388c21493\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built fire sentence-transformers pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, pathtools, faiss-cpu, exifread-nocycle, dataclasses, braceexpand, aniso8601, webdataset, urllib3, smmap, shortuuid, setproctitle, pyarrow, protobuf, MarkupSafe, itsdangerous, ftfy, fsspec, fire, docker-pycreds, click, Werkzeug, sentry-sdk, requests, Jinja2, gitdb, huggingface-hub, GitPython, flask, embedding-reader, wandb, transformers, timm, flask-restful, flask-cors, clip-anytorch, autofaiss, sentence-transformers, open-clip-torch, multilingual-clip, img2dataset, clip-retrieval\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: itsdangerous\n",
            "    Found existing installation: itsdangerous 1.1.0\n",
            "    Uninstalling itsdangerous-1.1.0:\n",
            "      Successfully uninstalled itsdangerous-1.1.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.1.0\n",
            "    Uninstalling fsspec-2023.1.0:\n",
            "      Successfully uninstalled fsspec-2023.1.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 Jinja2-3.1.2 MarkupSafe-2.1.2 Werkzeug-2.2.3 aniso8601-9.0.1 autofaiss-2.15.5 braceexpand-0.1.7 click-8.1.3 clip-anytorch-2.5.0 clip-retrieval-2.36.1 dataclasses-0.6 docker-pycreds-0.4.0 embedding-reader-1.5.0 exifread-nocycle-3.0.1 faiss-cpu-1.7.3 fire-0.4.0 flask-2.2.3 flask-cors-3.0.10 flask-restful-0.3.9 fsspec-2022.11.0 ftfy-6.1.1 gitdb-4.0.10 huggingface-hub-0.12.1 img2dataset-1.41.0 itsdangerous-2.1.2 multilingual-clip-1.0.10 open-clip-torch-2.15.0 pathtools-0.1.2 protobuf-3.20.3 pyarrow-7.0.0 requests-2.28.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 sentry-sdk-1.15.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 timm-0.6.12 tokenizers-0.13.2 transformers-4.26.1 urllib3-1.26.14 wandb-0.12.21 webdataset-0.2.33\n"
          ]
        }
      ],
      "source": [
        "%pip install clip-retrieval img2dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ./clip-requirements.txt"
      ],
      "metadata": {
        "id": "JgQ7gYrPiCpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwPl2iEvCJZs"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "owNhU4KJCJZs"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from clip_retrieval.clip_client import ClipClient, Modality\n",
        "\n",
        "IMAGE_BASE_URL = \"https://github.com/rom1504/clip-retrieval/raw/main/tests/test_clip_inference/test_images/\"\n",
        "\n",
        "def log_result(result):\n",
        "    id, caption, url, similarity = result[\"id\"], result[\"caption\"], result[\"url\"], result[\"similarity\"]\n",
        "    print(f\"id: {id}\")\n",
        "    print(f\"caption: {caption}\")\n",
        "    print(f\"url: {url}\")\n",
        "    print(f\"similarity: {similarity}\")\n",
        "    display(Image(url=url, unconfined=True))\n",
        "\n",
        "client = ClipClient(\n",
        "    url=\"https://knn.laion.ai/knn-service\",\n",
        "    indice_name=\"laion5B-L-14\",\n",
        "    aesthetic_score=9,\n",
        "    aesthetic_weight=0.5,\n",
        "    modality=Modality.IMAGE,\n",
        "    num_images=10,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZkBruHYCJZs"
      },
      "source": [
        "## Query by text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zrsShOvZCJZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2f30c4-0a8b-4c3a-e202-d656a582bc1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'caption': 'orange cat with supicious look stock photo',\n",
              " 'url': 'https://media.istockphoto.com/photos/orange-cat-with-supicious-look-picture-id907595140?k=6&amp;m=907595140&amp;s=612x612&amp;w=0&amp;h=4CTvSxNvv4sxSCPxViryha4kAjuxDbrXM5vy4VPOuzk=',\n",
              " 'id': 518836491,\n",
              " 'similarity': 0.5591729879379272}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "cat_results = client.query(text=\"an image of a cat\")\n",
        "cat_results[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3tK7fWCJZs"
      },
      "source": [
        "## Query by image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O0CEQh4CJZs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "d3f37be8-e87b-4c5c-8346-1e432299a97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 574870177\n",
            "caption: Palm trees in Orlando, Florida\n",
            "url: https://www.polefitfreedom.com/wp-content/uploads/2018/03/Orlando.jpg\n",
            "similarity: 0.961936354637146\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://www.polefitfreedom.com/wp-content/uploads/2018/03/Orlando.jpg\" class=\"unconfined\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "beach_results = client.query(image=\"https://github.com/rom1504/clip-retrieval/raw/main/tests/test_clip_inference/test_images/321_421.jpg\")\n",
        "log_result(beach_results[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo6kCLzlCJZt"
      },
      "source": [
        "## Query by embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import clip  # pylint: disable=import-outside-toplevel\n",
        "import torch\n",
        "\n",
        "model, preprocess = clip.load(\"ViT-L/14\", device=\"cpu\", jit=True)"
      ],
      "metadata": {
        "id": "4MXCxNH4ehZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f952b93-2c21-4274-dcd4-53edc218fbc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 933M/933M [00:05<00:00, 180MiB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/clip/clip.py:160: FutureWarning: 'torch.onnx._patch_torch._node_getitem' is deprecated in version 1.13 and will be removed in version 1.14. Please Internally use '_node_get' in symbolic_helper instead..\n",
            "  if \"value\" in node.attributeNames() and str(node[\"value\"]).startswith(\"cuda\"):\n",
            "/usr/local/lib/python3.8/dist-packages/clip/clip.py:186: FutureWarning: 'torch.onnx._patch_torch._node_getitem' is deprecated in version 1.13 and will be removed in version 1.14. Please Internally use '_node_get' in symbolic_helper instead..\n",
            "  if inputs[i].node()[\"value\"] == 5:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "36o8libuCJZt"
      },
      "outputs": [],
      "source": [
        "# import clip  # pylint: disable=import-outside-toplevel\n",
        "# import torch\n",
        "\n",
        "# model, preprocess = clip.load(\"ViT-L/14\", device=\"cpu\", jit=True)\n",
        "\n",
        "import urllib\n",
        "import io\n",
        "import numpy as np\n",
        "def download_image(url):\n",
        "    urllib_request = urllib.request.Request(\n",
        "        url,\n",
        "        data=None,\n",
        "        headers={\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:72.0) Gecko/20100101 Firefox/72.0\"},\n",
        "    )\n",
        "    with urllib.request.urlopen(urllib_request, timeout=10) as r:\n",
        "        img_stream = io.BytesIO(r.read())\n",
        "    return img_stream\n",
        "def normalized(a, axis=-1, order=2):\n",
        "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
        "    l2[l2 == 0] = 1\n",
        "    return a / np.expand_dims(l2, axis)\n",
        "\n",
        "def get_text_emb(text):\n",
        "    with torch.no_grad():\n",
        "        text_emb = model.encode_text(clip.tokenize([text], truncate=True).to(\"cpu\"))\n",
        "        text_emb /= text_emb.norm(dim=-1, keepdim=True)\n",
        "        text_emb = text_emb.cpu().detach().numpy().astype(\"float32\")[0]\n",
        "    return text_emb\n",
        "\n",
        "from PIL import Image as pimage\n",
        "\n",
        "def get_image_emb(image_path):\n",
        "    with torch.no_grad():\n",
        "        image = pimage.open(image_path)\n",
        "        image_emb = model.encode_image(preprocess(image).unsqueeze(0).to(\"cpu\"))\n",
        "        image_emb /= image_emb.norm(dim=-1, keepdim=True)\n",
        "        image_emb = image_emb.cpu().detach().numpy().astype(\"float32\")[0]\n",
        "        return image_emb\n",
        "\n",
        "def get_image_url_emb(image_url):\n",
        "    succeed = True\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "          image = pimage.open(download_image(image_url))\n",
        "        except:\n",
        "          print(\"error in reading url\")\n",
        "          succeed = False\n",
        "          return succeed, []\n",
        "        image_emb = model.encode_image(preprocess(image).unsqueeze(0).to(\"cpu\"))\n",
        "        image_emb /= image_emb.norm(dim=-1, keepdim=True)\n",
        "        image_emb = image_emb.cpu().detach().numpy().astype(\"float32\")[0]\n",
        "        return succeed, image_emb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_emb = get_image_emb(\"/content/test_imgs/Bryant/1581826075_bam-adebayo-skills.jpg\")"
      ],
      "metadata": {
        "id": "WqKhfmTBEOYi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_emb_result = client.query(embedding_input=test_emb.tolist())"
      ],
      "metadata": {
        "id": "zGagMzvfFUpm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = test_emb_result[0]['url']\n",
        "print(url)\n",
        "succeed, test_emb = get_image_url_emb(url)\n",
        "print(len(test_emb_result))\n",
        "print(succeed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK3qbcypFj4p",
        "outputId": "970ceec3-e2c9-40b6-df2d-3b9c6fad9b32"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://cdn.noticialdia.com/wp-content/uploads/2020/02/EQ4tiTVXsAERGrY-220x160.jpg\n",
            "error in reading url\n",
            "8\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_emb.shape"
      ],
      "metadata": {
        "id": "D6BsZSZMEqtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "telVY60CCJZt"
      },
      "outputs": [],
      "source": [
        "red_tshirt_text_emb =  get_text_emb(\"red tshirt\")\n",
        "red_tshirt_results = client.query(embedding_input=red_tshirt_text_emb.tolist())\n",
        "log_result(red_tshirt_results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p3dYImsCJZt"
      },
      "outputs": [],
      "source": [
        "blue_dress_image_emb = get_image_emb(\"https://rukminim1.flixcart.com/image/612/612/kv8fbm80/dress/b/5/n/xs-b165-royal-blue-babiva-fashion-original-imag86psku5pbx2g.jpeg?q=70\")\n",
        "blue_dress_results = client.query(embedding_input=blue_dress_image_emb.tolist())\n",
        "log_result(blue_dress_results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POmMvyECCJZt"
      },
      "outputs": [],
      "source": [
        "red_tshirt_text_emb =  get_text_emb(\"red tshirt\")\n",
        "blue_dress_image_emb = get_image_emb(\"https://rukminim1.flixcart.com/image/612/612/kv8fbm80/dress/b/5/n/xs-b165-royal-blue-babiva-fashion-original-imag86psku5pbx2g.jpeg?q=70\")\n",
        "mean_emb = normalized(red_tshirt_text_emb + blue_dress_image_emb)[0]\n",
        "mean_results = client.query(embedding_input=mean_emb.tolist())\n",
        "log_result(mean_results[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tok9eHToCJZu"
      },
      "source": [
        "## Download and format a dataset from the results of a query\n",
        "\n",
        "If you have some images of your own, you can query each one and collect the results into a custom dataset (a small subset of LAION-5B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbIa3watCJZu",
        "outputId": "b7e6a0aa-481c-4a06-89fc-05199699fca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:19<00:00,  2.84s/it]\n"
          ]
        }
      ],
      "source": [
        "# Create urls from known images in repo\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "test_images = [f\"{IMAGE_BASE_URL}{image}\" for image in [\"123_456.jpg\", \"208_495.jpg\", \"321_421.jpg\", \"389_535.jpg\", \"416_264.jpg\", \"456_123.jpg\", \"524_316.jpg\"]]\n",
        "\n",
        "# Re-initialize client with higher num_images\n",
        "client = ClipClient(url=\"https://knn.laion.ai/knn-service\", indice_name=\"laion5B-L-14\", num_images=40)\n",
        "\n",
        "# Run one query per image\n",
        "combined_results = []\n",
        "for image in tqdm(test_images):\n",
        "    combined_results.extend(client.query(image=image))\n",
        "\n",
        "# Save results to json file\n",
        "with open(\"search-results.json\", \"w\") as f:\n",
        "    json.dump(combined_results, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3eEYVLlCJZu",
        "outputId": "eb122a04-ef4f-4bfe-b490-8f919d2060d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the downloading of this file\n",
            "Sharding file number 1 of 1 called /content/search-results.json\n",
            "\r0it [00:00, ?it/s]File sharded in 1 shards\n",
            "Downloading starting now, check your bandwidth speed (with bwm-ng)your cpu (with htop), and your disk usage (with iotop)!\n",
            "1it [00:18, 18.05s/it]\n",
            "worker  - success: 0.829 - failed to download: 0.171 - failed to resize: 0.000 - images per sec: 7 - count: 76\n",
            "total   - success: 0.829 - failed to download: 0.171 - failed to resize: 0.000 - images per sec: 7 - count: 76\n"
          ]
        }
      ],
      "source": [
        "!img2dataset \"search-results.json\" --input_format=\"json\" --caption_col \"caption\" --output_folder=\"laion-enhanced-dataset\" --resize_mode=\"no\" --output_format=\"files\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Kaggle Dataset"
      ],
      "metadata": {
        "id": "jg59CBvT1lmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from google.colab import files\n",
        "files.upload() #this will prompt you to upload the kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "kQYWtutP21wJ",
        "outputId": "adfd613e-b382-4848-93ab-940d20cb08e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a60c627e-c26e-4826-983c-a8775b162962\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a60c627e-c26e-4826-983c-a8775b162962\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mengrandai\",\"key\":\"91421ab6c0080dca4830b41e1a398459\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-L1R08J3YLg",
        "outputId": "4e0982d4-e283-465d-f982-0667063a1012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 66 Feb 27 03:14 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "0BnqfeJU3cR2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "2wBzoYys3f9q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeG6vxg38E1Q",
        "outputId": "2981a4aa-59b0-4054-bcbc-fd65fc7c6111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d djjerrish/nba-player-image-dataset-201920"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpTP3J-t1ob3",
        "outputId": "9477d152-73a5-4d7d-8523-c47481399613"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading nba-player-image-dataset-201920.zip to /content\n",
            "100% 14.3G/14.3G [01:57<00:00, 47.6MB/s]\n",
            "100% 14.3G/14.3G [01:57<00:00, 131MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip nba-player-image-dataset-201920.zip"
      ],
      "metadata": {
        "id": "ixW928gT4HZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLYuP9d2CJZu"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "import os\n",
        "print(f\"Done! Download/copy the contents of {os.getcwd()}/laion-enhanced-dataset/\")\n",
        "!realpath laion-enhanced-dataset/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "!wget https://openaipublic.azureedge.net/clip/data/country211.tgz\n",
        "!tar zxvf country211.tgz"
      ],
      "metadata": {
        "id": "iTFrXhSVGUEA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "PS0FVwbPGYXW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "!ls country211/test/AD/1320521_42.455507_1.462726.jpg"
      ],
      "metadata": {
        "id": "v-ONU0feItd7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "len(test_result)"
      ],
      "metadata": {
        "id": "x30DDQfhJfiJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dict = {'kobe':[1,2,3,4],'lebron':[5,6,7,8]}\n",
        "player_list = []"
      ],
      "metadata": {
        "id": "ZLqzvzW_KyOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each_player in player_list:\n",
        "  embedding_dict = {}\n",
        "  for each_img in image_dict[each_player]:\n",
        "    # Find the embedding \n",
        "    player_image_emb = get_image_emb(each_img)\n",
        "    embedding_dict[each_player].append(player_image_emb)\n",
        "\n",
        "# Calculate 95% threshold on distance\n",
        "# t\n",
        "\n",
        "\n",
        "# data poisoning\n",
        "# 1. Fawkes embedding\n",
        "\n",
        "# 2. Lowkey embedding\n",
        "\n",
        "# 3. original embedding\n",
        "\n",
        "'''\n",
        "poisoning = [original, Fawkes, Lowkey]\n",
        "for each embedding in image_emb:\n",
        "  for poison in poisoning:\n",
        "    if Fawkes or Lowkey:\n",
        "      embedding = generate_poisoning(embedding)\n",
        "    test_result = client.query(embedding_input=embedding.tolist())\n",
        "    length = len(test_result)\n",
        "    for result in test_result:\n",
        "      result_emb = get_image_emb(result)\n",
        "      dist = distance(result_emb, embedding)\n",
        "      if dist > t:\n",
        "        # remove result from test_result\n",
        "      new_length = len(test(result))\n",
        "      accuracy[poison] += new_length / length\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "nBqP6o-RKvd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "rootdir = \"/content\"\n",
        "\n",
        "def generate_poisoning(root):\n",
        "  source_dir = \"./test_imgs\"\n",
        "  target_dir = \"./test_imgs_Fawkes\"\n",
        "  os.makedirs(os.path.join(rootdir, 'test_imgs_Fawkes'), exist_ok=True)\n",
        "  img_list = os.listdir(source_dir)\n",
        "  for img_name in img_list:\n",
        "    if \"_cloaked\" in img_name:\n",
        "      shutil.move(os.path.join(source_dir, img_name), target_dir)\n",
        "\n",
        "poisoning = [original,fawkes,lowkey]\n",
        "\n",
        "# def calculate_threshold(image_emb):\n",
        "  \n",
        "def original_search(image_emb,t):\n",
        "  acc_list = []\n",
        "  for embedding in image_emb:\n",
        "    search_result = client.query(embedding_input = embedding.tolist())\n",
        "    length = len(search_result)\n",
        "    tmp_list = []\n",
        "    for result in search_result:\n",
        "      result_emb = get_image_emb(result)\n",
        "      distance = torch.dist(result_emb,embedding) \n",
        "      if distance < t:\n",
        "        tmp_list.append(result)\n",
        "    acc = len(tmp_list)/length\n",
        "    \n",
        "    \n",
        "    acc_list.append(acc)\n",
        "    final_acc = sum(acc_list)/len(acc_list)\n"
      ],
      "metadata": {
        "id": "OP23eCoDQ9ns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "e56e9ffb-dd90-4659-e9d9-0f5ec7153622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7e31e1ea32cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpoisoning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfawkes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# def calculate_threshold(image_emb):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'original' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = {}\n",
        "a['a'] = [1,2]\n",
        "\n",
        "t = np.percentile((img_emb - embedding),95)\n",
        "abs(img_emb-embedding).shape"
      ],
      "metadata": {
        "id": "shDGXtnlbBoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b87792-85c0-433f-8e14-1106e8b30d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tqdm\n",
        "player_rootdir = '/content/test_imgs'\n",
        "player_names = os.listdir(player_rootdir) \n",
        "accuracy_for_players = {}\n",
        "total_acc = []\n",
        "for player in player_names:\n",
        "  # generate_poisoning(player)\n",
        "  # Generate embedding for each image for this one player\n",
        "  img_emb = []\n",
        "  for player_img in os.listdir(os.path.join(player_rootdir, player)):\n",
        "    print(player_img)\n",
        "    img_emb.append(get_image_emb(os.path.join(player_rootdir, player, player_img)))\n",
        "    accuracy_for_players[player] = []\n",
        "  # Now, set one embedding as the query image and calculate the accuracy for this image\n",
        "  acc_list = []\n",
        "  for embedding in img_emb:\n",
        "    # Calculate threshold\n",
        "    # exclued_list = [x for x in img_emb if x != embedding]\n",
        "    t = np.percentile(abs(img_emb-embedding),95)\n",
        "    # Query image from client\n",
        "    search_result = client.query(embedding_input = embedding.tolist())\n",
        "    length = len(search_result)\n",
        "    if length == 0:\n",
        "      continue\n",
        "    tmp_list = []\n",
        "    for result in search_result:\n",
        "      url = result['url']\n",
        "      succeed, result_emb = get_image_url_emb(url)\n",
        "      # result_emb = get_image_emb(result)\n",
        "      if succeed:\n",
        "        distance = torch.dist(torch.from_numpy(result_emb),torch.from_numpy(embedding)) \n",
        "        #if distance < t:\n",
        "        tmp_list.append(result)\n",
        "    acc = len(tmp_list)/length\n",
        "    total_acc = total_acc.append(acc)\n",
        "    acc_list.append(acc)\n",
        "  accuracy_for_players[player] = acc_list\n",
        "\n",
        "total_acc = sum(total_acc)/len(total_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q15ytg4QW0ZH",
        "outputId": "88ff91f3-74f1-4c98-879f-fdaff888ed06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20160330_MCDAAG_Bam_Adebayo_with_the_ball.jpg\n",
            "600_BAM_191021.jpg\n",
            "5c9ec4bc7745a19ec1b82022fe5c1f5d.jpg\n",
            "600-bamadebayo-1819.jpg\n",
            "1581826075_bam-adebayo-skills.jpg\n",
            "error in reading url\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_for_players"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDP_Jm3zhjGO",
        "outputId": "7f2c02b9-25da-4907-eb58-c92c0b7691e3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bryant': [0.875, 0.75, 0.8, 0.7777777777777778, 0.625],\n",
              " 'Kobe': [0.8888888888888888, 0.6666666666666666, 1.0, 1.0],\n",
              " '.ipynb_checkpoints': []}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "id": "iLxY4UiMtu3l",
        "outputId": "9b38be4e-3a52-44a5-df27-36c755b3c793",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.26193094e-03, -7.36073125e-03,  3.52005139e-02, -3.86628732e-02,\n",
              "        7.00690178e-03,  8.36333260e-03,  2.18387414e-02, -6.88996017e-02,\n",
              "       -1.39928823e-02, -3.81393097e-02,  5.52185811e-02, -2.38364488e-02,\n",
              "       -3.54156271e-02, -1.60567351e-02,  2.19645374e-03,  2.90458906e-03,\n",
              "       -2.21172199e-02,  3.65848164e-03,  4.35853703e-03, -2.06869934e-02,\n",
              "        1.30347803e-03, -1.91280935e-02,  1.21400692e-03, -1.83871575e-02,\n",
              "       -1.69272721e-02, -3.86946043e-03,  1.04569308e-02, -3.89016815e-03,\n",
              "        1.32933408e-02, -1.90918334e-02,  7.26179825e-03,  1.64105576e-02,\n",
              "        5.58401179e-03,  3.73299308e-02, -7.11320667e-03, -6.67892816e-03,\n",
              "       -2.70802388e-03, -1.73460320e-02,  1.20684998e-02, -2.42227241e-02,\n",
              "        2.48038340e-02, -1.37646580e-02, -2.29405109e-02, -1.62309445e-02,\n",
              "       -3.97432782e-02,  1.00548984e-02, -4.97802719e-02, -3.83437276e-02,\n",
              "       -4.28111404e-02, -4.02664877e-02, -3.97639424e-02,  5.29251248e-03,\n",
              "        1.34622771e-02,  2.85709347e-03, -3.70498979e-03, -5.66917695e-02,\n",
              "        6.17974717e-03, -2.39338521e-02,  6.38992479e-03, -2.32341303e-03,\n",
              "        2.43975613e-02, -1.22506879e-02,  3.15154716e-02,  1.76013950e-02,\n",
              "        1.91382915e-02, -1.86345577e-02, -3.92335877e-02, -2.66332459e-02,\n",
              "       -5.56874909e-02,  1.11510940e-02,  1.17557799e-03,  2.01940220e-02,\n",
              "        6.72852807e-03, -1.83735676e-02,  1.88657492e-02,  4.13754322e-02,\n",
              "       -3.89474705e-02, -4.41463524e-03,  1.18838567e-02, -1.26751408e-03,\n",
              "       -2.03460921e-03,  6.46828189e-02, -1.66035891e-02, -4.22382867e-03,\n",
              "        5.48515730e-02, -1.07531594e-02,  2.23324914e-02,  3.07653565e-02,\n",
              "        2.75601409e-02,  2.52178404e-02, -3.79180396e-03, -4.15798277e-03,\n",
              "        7.97097292e-03,  2.13064458e-02,  5.04263267e-02, -1.17861554e-02,\n",
              "       -3.07208020e-02, -9.24682617e-02,  1.45035572e-02,  2.35363040e-02,\n",
              "       -5.61999939e-02, -3.92642654e-02, -1.49591444e-02, -1.24435434e-02,\n",
              "        3.60212810e-02, -2.02338910e-03,  2.10984959e-03,  1.00871073e-02,\n",
              "        1.02242641e-02,  4.70938571e-02, -2.29893494e-02, -4.04712372e-02,\n",
              "       -2.65195537e-02,  3.13974060e-02, -3.11278123e-02, -2.53875684e-02,\n",
              "       -1.18975090e-02, -1.58214327e-02, -2.24348437e-03,  7.22808670e-03,\n",
              "        4.30087633e-02, -6.23362958e-02, -9.81889758e-03,  1.46244625e-02,\n",
              "       -6.33932576e-02,  2.44260486e-03, -6.81113731e-03,  2.13414989e-02,\n",
              "       -2.75791511e-02, -4.99110762e-03,  2.37241108e-03, -8.72614682e-02,\n",
              "        2.41205953e-02, -1.44932565e-04,  1.26446271e-02,  1.47003904e-02,\n",
              "        2.04921011e-02,  2.95835175e-02,  7.26241097e-02, -1.91703606e-02,\n",
              "       -8.73221550e-03,  5.01108021e-02,  2.69124620e-02, -1.12992944e-02,\n",
              "       -4.29783724e-02,  1.87429506e-02,  1.81324054e-02, -2.20811162e-02,\n",
              "       -1.58442520e-02,  3.06629464e-02,  2.40339581e-02, -3.67089175e-02,\n",
              "        1.57200056e-03,  2.71790195e-03,  6.77129021e-03,  2.69193929e-02,\n",
              "        1.55233936e-02, -2.25642417e-02, -4.40692604e-02,  1.69566814e-02,\n",
              "        9.97718744e-05,  1.22355614e-02,  7.46080326e-03, -2.63559185e-02,\n",
              "        5.51054720e-03,  7.99963474e-02, -3.65863852e-02,  5.80473524e-03,\n",
              "       -2.26974650e-03,  3.63835916e-02,  2.31144018e-02, -2.79681454e-03,\n",
              "       -3.71105000e-02,  1.46955699e-02,  2.56514978e-02,  2.71691479e-05,\n",
              "       -3.66828144e-02, -7.04712793e-02,  2.88640372e-02, -3.76916165e-03,\n",
              "        9.00239721e-02,  5.67294192e-03,  2.00720560e-02, -1.80347767e-02,\n",
              "        5.25453165e-02,  1.82855278e-02, -2.75207683e-02, -2.53864657e-02,\n",
              "        6.25933101e-03, -3.11194658e-02, -5.60544357e-02,  1.63440928e-02,\n",
              "        3.99607942e-02,  1.06443921e-02, -1.58480220e-02, -3.70706283e-02,\n",
              "       -1.24692945e-02,  5.32499477e-02, -3.89523758e-03, -2.32259296e-02,\n",
              "       -1.16592078e-02, -6.21805899e-04, -5.65581117e-03,  4.38790433e-02,\n",
              "       -5.51260337e-02,  1.51667483e-02, -1.07157379e-02,  1.05423033e-02,\n",
              "        5.77061959e-02,  9.19307303e-03,  2.80076638e-02,  4.88017499e-03,\n",
              "       -3.05728130e-02, -6.85700728e-03,  4.88289371e-02,  3.13429125e-02,\n",
              "        1.40782706e-02,  2.29607560e-02,  1.26939267e-02,  2.60929298e-02,\n",
              "       -3.57333338e-03, -1.57258250e-02, -6.83681050e-04,  5.58336861e-02,\n",
              "       -9.94220562e-03,  1.61145050e-02, -5.08176424e-02,  1.73884258e-02,\n",
              "        4.28876057e-02, -2.74203103e-02, -4.02489342e-02, -1.84751078e-02,\n",
              "        1.52139394e-02,  5.49121350e-02, -2.34648176e-02,  1.61320753e-02,\n",
              "        1.76613666e-02,  4.34218124e-02,  3.83192413e-02, -6.11559674e-03,\n",
              "       -5.39267287e-02,  1.59814488e-02, -1.52065046e-02, -2.17254777e-02,\n",
              "       -4.34068823e-03,  2.60432586e-02,  1.56850219e-02,  5.28716668e-02,\n",
              "        1.61817707e-02,  5.45094023e-03, -3.79102118e-02, -3.08970138e-02,\n",
              "        1.31031300e-03,  2.12012660e-02, -1.29420497e-02, -2.42222920e-02,\n",
              "       -2.33659502e-02, -1.50710195e-02,  1.16200494e-02, -1.10102131e-03,\n",
              "       -4.31118570e-02,  1.90964732e-02,  1.14686752e-03,  1.64876319e-02,\n",
              "       -2.63997968e-02,  3.41299847e-02,  2.13087611e-02,  3.33290547e-02,\n",
              "       -4.40663062e-02, -2.68987138e-02, -1.26666781e-02,  1.30306017e-02,\n",
              "       -2.03986242e-02,  3.51420119e-02, -1.78652350e-02,  3.88400070e-03,\n",
              "        1.91091578e-02, -9.39924066e-05, -5.25736250e-03, -1.50061958e-03,\n",
              "        2.78358478e-02, -2.59892875e-03,  1.31585523e-02,  1.06605226e-02,\n",
              "       -5.29869087e-03,  1.16271246e-02, -4.41868193e-02, -1.95698757e-02,\n",
              "       -2.71354243e-02, -2.92597368e-04, -6.06413446e-02,  2.15225834e-02,\n",
              "       -2.68906122e-03, -3.78349796e-02,  4.56314050e-02,  8.55170749e-03,\n",
              "       -2.21631154e-02,  2.00281423e-02,  2.12942064e-02, -1.37903774e-02,\n",
              "        1.44826472e-02, -2.29682513e-02, -1.15350178e-02,  2.25921348e-02,\n",
              "       -1.35350153e-02,  9.28282086e-03, -2.13613231e-02,  4.80572060e-02,\n",
              "        1.30235106e-02, -1.28557086e-02, -2.81728269e-03, -2.07170490e-02,\n",
              "       -1.26492260e-02, -1.76191665e-02,  7.04997331e-02, -3.14292237e-02,\n",
              "       -6.59427568e-02,  1.64482333e-02, -1.54128550e-02,  5.52000664e-03,\n",
              "       -3.06203142e-02, -9.99287516e-03,  1.93227828e-02, -5.17284265e-03,\n",
              "       -1.76489316e-02,  1.97582366e-03,  1.95446573e-02, -3.37959118e-02,\n",
              "        4.10784520e-02,  3.23668793e-02,  7.29979994e-03, -1.06441928e-02,\n",
              "       -6.40971959e-02, -4.02052514e-03, -3.57356598e-03, -1.24418857e-02,\n",
              "        2.44244025e-03, -3.41465510e-02, -3.23247910e-02, -7.96945021e-02,\n",
              "        4.02290076e-02,  5.26830852e-02,  5.82700362e-03,  2.18165461e-02,\n",
              "       -9.72104911e-03,  1.08177094e-02, -2.16747541e-02,  3.85865606e-02,\n",
              "       -1.09560089e-02,  1.44139519e-02,  1.21702645e-02, -1.33569129e-02,\n",
              "        1.89281953e-03, -1.32977692e-02, -5.49994223e-03,  2.00475170e-03,\n",
              "        2.49946695e-02,  3.53773534e-02,  2.17207540e-02,  1.54386042e-02,\n",
              "        7.48053193e-02, -8.26738589e-03, -3.02560657e-04, -5.03263948e-03,\n",
              "        1.67713687e-02, -3.27065438e-02, -2.63453033e-02,  6.20752992e-03,\n",
              "       -3.39304879e-02, -3.23575214e-02, -1.75559055e-02, -3.08765378e-02,\n",
              "       -6.02807757e-03,  3.49678419e-04, -3.75227965e-02, -5.56382537e-03,\n",
              "       -2.15401556e-02, -1.59944296e-02,  1.18376119e-02,  2.95642018e-02,\n",
              "        1.73551887e-02,  3.29768518e-04,  2.79128626e-02,  5.28530665e-02,\n",
              "       -1.10003119e-02,  3.31627466e-02,  9.10557341e-03,  3.16100987e-03,\n",
              "        2.75155939e-02, -9.14800912e-03,  2.16439646e-03, -2.24935375e-02,\n",
              "        1.83583610e-02,  7.02954978e-02,  2.05746684e-02, -8.06921453e-04,\n",
              "        2.34865081e-02, -2.97428928e-02,  1.30102849e-02,  1.66115593e-02,\n",
              "        3.64349037e-02,  6.34408230e-03, -3.78690697e-02,  3.30244824e-02,\n",
              "        5.21129146e-02,  4.24737036e-02,  2.05831509e-02, -6.42580027e-03,\n",
              "       -7.21273059e-03, -1.77685302e-02, -3.35230194e-02,  2.43447553e-02,\n",
              "       -2.73306593e-02, -3.66793931e-01,  3.29392329e-02,  2.79344711e-02,\n",
              "        2.70721242e-02,  3.68932262e-02,  2.47320551e-02, -1.44653916e-02,\n",
              "        4.95879017e-02, -2.75792424e-02, -1.30142020e-02, -1.62691067e-04,\n",
              "        1.15956692e-02,  3.78067195e-02,  3.27362516e-03, -1.80395711e-02,\n",
              "       -2.47090589e-02, -1.96375456e-02,  3.99078615e-02,  1.73679609e-02,\n",
              "        2.74199378e-02,  3.63796912e-02, -5.87540073e-03,  7.69234868e-03,\n",
              "       -3.50313671e-02,  6.50086254e-02,  4.06847801e-03, -1.65843368e-02,\n",
              "        5.52776940e-02,  9.55215015e-04, -2.61131953e-02,  2.46451851e-02,\n",
              "        4.09682579e-02,  5.67358136e-02,  4.45089210e-03,  2.37280466e-02,\n",
              "        6.56385720e-03,  4.34258133e-02,  5.51919155e-02,  2.28356924e-02,\n",
              "        1.90034695e-03,  5.52740926e-03,  2.04766560e-02, -5.71009554e-02,\n",
              "        5.76780364e-03, -2.99803317e-02, -1.83625519e-02, -1.81054696e-02,\n",
              "       -3.98922302e-02, -2.83351317e-02, -1.09116714e-02, -1.85943693e-02,\n",
              "       -1.10824192e-02,  3.14753056e-02, -4.66081686e-02,  1.36590376e-01,\n",
              "        1.82347540e-02,  2.43679597e-03,  3.45972143e-02, -1.04558216e-02,\n",
              "       -3.12472712e-02, -1.98065285e-02, -5.11920750e-02,  3.06684691e-02,\n",
              "       -7.88696390e-03, -1.39637925e-02,  2.52433121e-02,  1.58310856e-03,\n",
              "       -2.62876544e-02, -9.86899529e-03, -8.85911211e-02, -3.33690383e-02,\n",
              "        2.63069961e-02, -1.49435578e-02, -6.67307875e-04, -3.03476155e-02,\n",
              "       -1.47292260e-02,  5.35958149e-02, -2.48290282e-02, -3.82462665e-02,\n",
              "       -2.24495959e-02, -4.47419770e-02,  1.41721703e-02,  2.60272529e-02,\n",
              "       -4.18174127e-03,  1.54145679e-03,  6.73415288e-02, -8.29750486e-03,\n",
              "       -9.30575468e-03,  1.96340475e-02, -3.39996163e-03,  8.71889060e-04,\n",
              "        1.97269674e-02, -5.51086329e-02, -1.20553952e-02,  6.51887283e-02,\n",
              "        7.27852881e-02,  1.03450594e-02,  4.60622506e-03, -1.68667361e-02,\n",
              "        5.31758182e-02,  1.73332915e-02, -7.14775827e-03, -3.51312966e-03,\n",
              "       -2.45400388e-02, -1.69806257e-02, -4.63168137e-03, -1.48983076e-02,\n",
              "       -3.84670459e-02,  6.15074039e-02,  3.58330295e-03,  3.95867135e-03,\n",
              "       -3.70480269e-02,  6.35906756e-02,  3.08652557e-02, -6.60878345e-02,\n",
              "        6.67553693e-02, -2.14738138e-02, -8.94664135e-03,  1.63534470e-02,\n",
              "        1.01008089e-02, -4.08213362e-02,  1.45150786e-02, -8.91172290e-02,\n",
              "       -2.25040596e-02,  2.21012793e-02,  2.02329792e-02, -3.94205786e-02,\n",
              "       -5.63798100e-03, -1.91464729e-04,  2.69496553e-02,  4.44096737e-02,\n",
              "        4.73099574e-02,  5.14620636e-03,  2.84331944e-03,  1.98915582e-02,\n",
              "        2.62890961e-02,  3.03004570e-02, -9.37179942e-03,  5.33031002e-02,\n",
              "        5.11110984e-02,  2.76844855e-02, -5.62624540e-04, -2.50744428e-02,\n",
              "       -8.45793337e-02, -5.87405264e-02,  3.56025361e-02,  3.33334156e-03,\n",
              "        5.09961396e-02,  2.65746154e-02, -2.47797724e-02,  6.29154146e-02,\n",
              "        1.41394483e-02, -1.04178339e-02, -1.76766654e-04,  1.50439783e-03,\n",
              "        2.33964268e-02, -2.92934179e-02,  3.58814485e-02, -3.97549048e-02,\n",
              "       -4.70257476e-02,  2.53600329e-02, -1.07927360e-02, -1.91388875e-02,\n",
              "        4.70942585e-03,  3.81278135e-02,  8.71974882e-03,  1.84700042e-02,\n",
              "       -2.03801133e-02,  1.30396327e-02, -2.39919703e-02,  2.38985308e-02,\n",
              "        3.42992358e-02, -2.41035949e-02, -1.51725691e-02,  1.89057663e-02,\n",
              "        2.11837213e-03,  2.08477098e-02, -3.52224484e-02,  1.12606101e-02,\n",
              "       -1.53653873e-02,  4.01510186e-02,  1.36710722e-02, -2.03898307e-02,\n",
              "        5.51131666e-02, -2.69910116e-02,  7.16367923e-03, -1.75778521e-03,\n",
              "       -4.51086685e-02,  2.01000031e-02,  3.53806876e-02,  4.65223603e-02,\n",
              "        3.43709216e-02,  1.53969517e-02,  1.71084364e-03, -2.57609133e-02,\n",
              "        1.09339310e-02, -1.09553989e-02,  1.64445303e-02, -5.98895997e-02,\n",
              "        3.40323076e-02, -1.20672686e-02,  4.96847853e-02,  3.88113372e-02,\n",
              "        2.70911343e-02, -2.92623099e-02,  5.28233266e-03,  1.01242261e-02,\n",
              "       -1.92061942e-02, -1.37562854e-02, -2.79878750e-02, -6.26842771e-03,\n",
              "       -2.69509037e-03, -6.71076849e-02, -2.37076040e-02,  2.58079246e-02,\n",
              "        1.71848910e-03,  5.21839364e-03, -4.03771400e-02,  4.09696326e-02,\n",
              "        1.56785231e-02,  1.02283871e-02,  3.26967537e-02, -1.36994421e-01,\n",
              "        1.31993545e-02, -2.93103661e-02, -2.81185322e-02, -4.84952983e-03,\n",
              "       -2.09865663e-02,  3.93854305e-02,  2.34473124e-02,  8.04641843e-03,\n",
              "        3.86941314e-01, -1.57189351e-02,  2.24548709e-02, -2.28704531e-02,\n",
              "        2.67786607e-02,  1.76027212e-02, -1.05256890e-03, -4.46237326e-02,\n",
              "       -1.81460902e-02, -2.99009848e-02, -4.48052324e-02, -3.68984379e-02,\n",
              "       -2.36541163e-02,  4.42392975e-02, -4.07697894e-02,  1.09520361e-01,\n",
              "       -3.87669466e-02,  2.12575286e-03,  1.37910396e-02,  1.47657450e-02,\n",
              "       -1.52652711e-03,  8.18152167e-03,  4.98281978e-03,  1.01607516e-02,\n",
              "        3.38357012e-03, -4.60448898e-02, -1.06292758e-02,  1.70516558e-02,\n",
              "        3.08474954e-02, -2.71085743e-02,  6.87798187e-02, -3.19185331e-02,\n",
              "        1.56018995e-02,  2.39171702e-02, -1.42753366e-02,  7.76876695e-03,\n",
              "       -4.26143222e-03,  4.35463246e-03, -1.53200701e-03,  2.40442194e-02,\n",
              "       -2.57874690e-02,  5.13672680e-02,  1.65864117e-02, -1.49565777e-02,\n",
              "        1.50348730e-02,  1.72054823e-02,  2.79390980e-02,  3.24537270e-02,\n",
              "        2.08657663e-02,  2.02309266e-02, -2.22884193e-02,  6.56871917e-03,\n",
              "        5.43423332e-02, -2.43943408e-02,  5.63119836e-02,  2.04822957e-03,\n",
              "       -1.09131057e-02, -2.10794862e-02, -6.00041403e-03, -4.56579262e-03,\n",
              "       -5.39961979e-02, -3.08789108e-02,  1.40197231e-02, -7.23082386e-03,\n",
              "       -2.88578216e-02, -1.98482331e-02, -5.48916087e-02,  4.87364363e-04,\n",
              "       -3.83302271e-02,  1.18161328e-02, -2.58605648e-02, -9.94914677e-03,\n",
              "        8.86704586e-03,  2.21479386e-02,  4.89586443e-02,  2.87197940e-02,\n",
              "        4.14782092e-02,  7.40034059e-02, -3.10510788e-02, -5.76215275e-02,\n",
              "        2.24468810e-03, -1.02784507e-01,  3.33556980e-02,  9.17180348e-03,\n",
              "        4.76915715e-03,  2.40416620e-02,  3.79606374e-02,  3.29041518e-02,\n",
              "        7.75320735e-03,  6.64550206e-03,  8.00522510e-03,  1.24040712e-02,\n",
              "        4.73319776e-02,  1.67051516e-02, -2.97142528e-02, -1.46606686e-02,\n",
              "        6.30691741e-03,  2.77831610e-02,  1.98699487e-03,  1.22021744e-02,\n",
              "        4.60481271e-04,  3.91176390e-03,  3.12524326e-02, -5.56595065e-03,\n",
              "        4.74563539e-02,  3.45360041e-02,  1.78762265e-02,  1.53163485e-02,\n",
              "       -1.31984148e-03,  7.79092778e-03,  2.82641780e-02,  6.96859583e-02,\n",
              "        4.91831899e-02,  1.84820294e-02, -4.59730588e-02, -3.60599719e-03,\n",
              "        8.73844884e-03, -3.71160805e-02,  8.90666433e-03, -3.62281129e-02,\n",
              "        3.49592417e-02,  5.00620715e-02, -1.52749689e-02,  3.90842147e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_emb = get_image_emb(\"https://storage.googleapis.com/kagglesdsdata/datasets/708260/1235942/NBA%20Players/Batum%2C%20Nicolas/513789904-e1459310098147.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20230225%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230225T060020Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=a25c8c397d6f2ceb36c49f287f25e594f60e0b4e98b6cd4a33bf3ad16b3460a27ba15c7c1da3bb3ea1187e966d07972ca274588908ba1b3dd95532dc2ee9dc62fe9c6535b0ab514bd7aff1e278b065e600bdbea88a6274a58826ae9444ff75e0d6acd0287c72c727b79f70c04f4766c801bc4c5a4c01d3b788603c4a7804967cb4915e20cd415bd01e7f259079c8cc39aca20bb82d1319d693a0d760545e65133522b04c1b83c475b160560479aa1084ce00c40b9646a1bc524f7d7a6e7c66f2758d12e78dbfabd0b298db3f3758198c2e9ff954ae637594f72d1be02cfd4b30ccfb24e45982f51ecbc0dddbd5264bd984d743a77cb07a0569c3b9a258b38bfd\")\n",
        "test_result = client.query(embedding_input=test_image_emb.tolist())\n",
        "log_result(test_result[11])"
      ],
      "metadata": {
        "id": "AufREnqUInLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_result(test_result[1])"
      ],
      "metadata": {
        "id": "ZVWLERcxJmbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pimage.open('country211/test/AD/1320521_42.455507_1.462726.jpg')"
      ],
      "metadata": {
        "id": "38E6YrzfJK3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fawkes"
      ],
      "metadata": {
        "id": "V2LJOTCrDw4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install fawkes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1JZUUMk6p6k",
        "outputId": "f81a45e0-7072-4e81-86bb-7de612b3ff1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fawkes\n",
            "  Downloading fawkes-1.0.4-py3-none-any.whl (24 kB)\n",
            "Collecting keras==2.4.3\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.8/dist-packages (from fawkes) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from fawkes) (1.22.4)\n",
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp38-cp38-manylinux2010_x86_64.whl (394.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.4/394.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from fawkes) (6.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras==2.4.3->fawkes) (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras==2.4.3->fawkes) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from keras==2.4.3->fawkes) (1.7.3)\n",
            "Collecting h5py\n",
            "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.19.5\n",
            "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1->fawkes) (0.38.4)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1->fawkes) (3.20.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1->fawkes) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1->fawkes) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1->fawkes) (0.2.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1->fawkes) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1->fawkes) (2.11.2)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach>=2.1.0->fawkes) (0.5.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from mtcnn->fawkes) (4.6.0.66)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->fawkes) (2.28.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (6.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (3.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (1.26.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->fawkes) (3.2.2)\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=2ccf43684e25c54d61e81ac7cb81661830849e27a69124cf78fe2d621514a908\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78582 sha256=9b7e73b8329141f5c93f18f48f0c4d42f766ef9d32f44ff45602379b9b784fc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, flatbuffers, numpy, grpcio, gast, absl-py, keras-preprocessing, h5py, keras, mtcnn, tensorflow, fawkes\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.1.21\n",
            "    Uninstalling flatbuffers-23.1.21:\n",
            "      Successfully uninstalled flatbuffers-23.1.21\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.1\n",
            "    Uninstalling grpcio-1.51.1:\n",
            "      Successfully uninstalled grpcio-1.51.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.5 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.32.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.32.0 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "clip-retrieval 2.36.1 requires h5py<4,>=3.1.0, but you have h5py 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-0.15.0 fawkes-1.0.4 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 keras-2.4.3 keras-preprocessing-1.1.2 mtcnn-0.1.1 numpy-1.19.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fawkes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PUyo7lV7Q6v",
        "outputId": "53e82685-12a3-4e6e-ec68-54f0a5dbea89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-27 03:38:01.717374: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Downloading data from http://mirror.cs.uchicago.edu/fawkes/files/extractor_2.h5\n",
            "161832960/161829576 [==============================] - 31s 0us/step\n",
            "Identify 0 files in the directory\n",
            "Identify 0 images in the directory\n",
            "No images in the directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fawkes -d ./imgs --mode low"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0k36v3b6xRU",
        "outputId": "0521b4db-df53-41c9-a68a-5802400bb0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-27 03:33:03.599564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2023-02-27 03:33:05.387819: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2023-02-27 03:33:05.388670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2023-02-27 03:33:06.013371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
            "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.56GiB deviceMemoryBandwidth: 1.41TiB/s\n",
            "2023-02-27 03:33:06.013446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2023-02-27 03:33:06.042262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2023-02-27 03:33:06.042385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2023-02-27 03:33:06.046598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2023-02-27 03:33:06.047020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2023-02-27 03:33:06.047293: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-02-27 03:33:06.048405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2023-02-27 03:33:06.048654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2023-02-27 03:33:06.048681: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-02-27 03:33:06.079407: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-27 03:33:06.079932: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2023-02-27 03:33:06.079975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-02-27 03:33:06.079983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
            "Identify 0 files in the directory\n",
            "Identify 0 images in the directory\n",
            "No images in the directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./fawkes/setup.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIlFarip9S5H",
        "outputId": "352fbec5-b51a-41ed-dc46-d0d0faa304f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"./fawkes/setup.py\", line 9, in <module>\n",
            "    with open(\"README.md\", \"r\") as fh:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'README.md'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ~\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQN9dUjq9aqw",
        "outputId": "88e4c19a-a17e-4268-aa09-08e35dad98be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/fawkes')\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LibKnhvN-UM2",
        "outputId": "018d191e-f6ff-4d84-be13-859b21fd9bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fawkes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 setup.py install"
      ],
      "metadata": {
        "id": "NeC35pl6-Yw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721b610c-39e4-435f-b1e7-bf724c840e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating fawkes.egg-info\n",
            "writing fawkes.egg-info/PKG-INFO\n",
            "writing dependency_links to fawkes.egg-info/dependency_links.txt\n",
            "writing entry points to fawkes.egg-info/entry_points.txt\n",
            "writing requirements to fawkes.egg-info/requires.txt\n",
            "writing top-level names to fawkes.egg-info/top_level.txt\n",
            "writing manifest file 'fawkes.egg-info/SOURCES.txt'\n",
            "reading manifest file 'fawkes.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'fawkes.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/fawkes\n",
            "copying fawkes/differentiator.py -> build/lib/fawkes\n",
            "copying fawkes/__init__.py -> build/lib/fawkes\n",
            "copying fawkes/utils.py -> build/lib/fawkes\n",
            "copying fawkes/__main__.py -> build/lib/fawkes\n",
            "copying fawkes/align_face.py -> build/lib/fawkes\n",
            "copying fawkes/protection.py -> build/lib/fawkes\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/fawkes\n",
            "copying build/lib/fawkes/differentiator.py -> build/bdist.linux-x86_64/egg/fawkes\n",
            "copying build/lib/fawkes/__init__.py -> build/bdist.linux-x86_64/egg/fawkes\n",
            "copying build/lib/fawkes/utils.py -> build/bdist.linux-x86_64/egg/fawkes\n",
            "copying build/lib/fawkes/__main__.py -> build/bdist.linux-x86_64/egg/fawkes\n",
            "copying build/lib/fawkes/align_face.py -> build/bdist.linux-x86_64/egg/fawkes\n",
            "copying build/lib/fawkes/protection.py -> build/bdist.linux-x86_64/egg/fawkes\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fawkes/differentiator.py to differentiator.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fawkes/__init__.py to __init__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fawkes/utils.py to utils.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fawkes/__main__.py to __main__.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fawkes/align_face.py to align_face.cpython-38.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fawkes/protection.py to protection.cpython-38.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fawkes.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fawkes.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fawkes.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fawkes.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fawkes.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fawkes.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying fawkes.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "creating dist\n",
            "creating 'dist/fawkes-1.0.2-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing fawkes-1.0.2-py3.8.egg\n",
            "creating /usr/local/lib/python3.8/dist-packages/fawkes-1.0.2-py3.8.egg\n",
            "Extracting fawkes-1.0.2-py3.8.egg to /usr/local/lib/python3.8/dist-packages\n",
            "Adding fawkes 1.0.2 to easy-install.pth file\n",
            "Installing fawkes script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/fawkes-1.0.2-py3.8.egg\n",
            "Processing dependencies for fawkes==1.0.2\n",
            "Searching for bleach==6.0.0\n",
            "Best match: bleach 6.0.0\n",
            "Adding bleach 6.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for mtcnn==0.1.1\n",
            "Best match: mtcnn 0.1.1\n",
            "Adding mtcnn 0.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Keras==2.4.3\n",
            "Best match: Keras 2.4.3\n",
            "Adding Keras 2.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tensorflow==2.4.1\n",
            "Best match: tensorflow 2.4.1\n",
            "Adding tensorflow 2.4.1 to easy-install.pth file\n",
            "Installing estimator_ckpt_converter script to /usr/local/bin\n",
            "Installing import_pb_to_tensorboard script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for webencodings==0.5.1\n",
            "Best match: webencodings 0.5.1\n",
            "Adding webencodings 0.5.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for opencv-python==4.6.0.66\n",
            "Best match: opencv-python 4.6.0.66\n",
            "Adding opencv-python 4.6.0.66 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for h5py==2.10.0\n",
            "Best match: h5py 2.10.0\n",
            "Adding h5py 2.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for wrapt==1.12.1\n",
            "Best match: wrapt 1.12.1\n",
            "Adding wrapt 1.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for gast==0.3.3\n",
            "Best match: gast 0.3.3\n",
            "Adding gast 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.2\n",
            "Best match: Keras-Preprocessing 1.1.2\n",
            "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tensorboard==2.11.2\n",
            "Best match: tensorboard 2.11.2\n",
            "Adding tensorboard 2.11.2 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for wheel==0.38.4\n",
            "Best match: wheel 0.38.4\n",
            "Adding wheel 0.38.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for protobuf==3.20.3\n",
            "Best match: protobuf 3.20.3\n",
            "Adding protobuf 3.20.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tensorflow-estimator==2.4.0\n",
            "Best match: tensorflow-estimator 2.4.0\n",
            "Adding tensorflow-estimator 2.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for grpcio==1.32.0\n",
            "Best match: grpcio 1.32.0\n",
            "Adding grpcio 1.32.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for astunparse==1.6.3\n",
            "Best match: astunparse 1.6.3\n",
            "Adding astunparse 1.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for typing-extensions==3.7.4.3\n",
            "Best match: typing-extensions 3.7.4.3\n",
            "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for absl-py==0.15.0\n",
            "Best match: absl-py 0.15.0\n",
            "Adding absl-py 0.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for google-pasta==0.2.0\n",
            "Best match: google-pasta 0.2.0\n",
            "Adding google-pasta 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for flatbuffers==1.12\n",
            "Best match: flatbuffers 1.12\n",
            "Adding flatbuffers 1.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for opt-einsum==3.3.0\n",
            "Best match: opt-einsum 3.3.0\n",
            "Adding opt-einsum 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Markdown==3.4.1\n",
            "Best match: Markdown 3.4.1\n",
            "Adding Markdown 3.4.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for google-auth==2.16.1\n",
            "Best match: google-auth 2.16.1\n",
            "Adding google-auth 2.16.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for requests==2.28.2\n",
            "Best match: requests 2.28.2\n",
            "Adding requests 2.28.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Werkzeug==2.2.3\n",
            "Best match: Werkzeug 2.2.3\n",
            "Adding Werkzeug 2.2.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for importlib-metadata==6.0.0\n",
            "Best match: importlib-metadata 6.0.0\n",
            "Adding importlib-metadata 6.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cachetools==5.3.0\n",
            "Best match: cachetools 5.3.0\n",
            "Adding cachetools 5.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for urllib3==1.26.14\n",
            "Best match: urllib3 1.26.14\n",
            "Adding urllib3 1.26.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for certifi==2022.12.7\n",
            "Best match: certifi 2022.12.7\n",
            "Adding certifi 2022.12.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for charset-normalizer==3.0.1\n",
            "Best match: charset-normalizer 3.0.1\n",
            "Adding charset-normalizer 3.0.1 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for MarkupSafe==2.1.2\n",
            "Best match: MarkupSafe 2.1.2\n",
            "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for zipp==3.14.0\n",
            "Best match: zipp 3.14.0\n",
            "Adding zipp 3.14.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for oauthlib==3.2.2\n",
            "Best match: oauthlib 3.2.2\n",
            "Adding oauthlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for fawkes==1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.21"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1itag4FXBTtI",
        "outputId": "5120c972-fee6-49c2-ef0b-c15b35d8c364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.21\n",
            "  Downloading numpy-1.21.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.2\n",
            "    Uninstalling numpy-1.24.2:\n",
            "      Successfully uninstalled numpy-1.24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "open-clip-torch 2.15.0 requires protobuf==3.20.*, but you have protobuf 3.19.6 which is incompatible.\n",
            "fawkes 1.0.4 requires keras==2.4.3, but you have keras 2.11.0 which is incompatible.\n",
            "fawkes 1.0.4 requires tensorflow==2.4.1, but you have tensorflow 2.11.0 which is incompatible.\n",
            "clip-retrieval 2.36.1 requires h5py<4,>=3.1.0, but you have h5py 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "fawkes 1.0.4 requires keras==2.4.3, \n",
        "fawkes 1.0.4 requires tensorflow==2.4.1,\n",
        "'''\n",
        "!pip install tensorflow==2.4.1\n",
        "!pip install keras==2.4.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VVxJXn2SBnzq",
        "outputId": "e4a498ca-cc7a-45b2-c6dd-41d08ba74f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.4.1\n",
            "  Using cached tensorflow-2.4.1-cp38-cp38-manylinux2010_x86_64.whl (394.4 MB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (3.19.6)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (0.38.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Collecting numpy~=1.19.2\n",
            "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (0.3.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (2.8.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.28.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.2.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (6.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.11.15->tensorboard~=2.4->tensorflow==2.4.1) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, flatbuffers, numpy, absl-py, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.1.21\n",
            "    Uninstalling flatbuffers-23.1.21:\n",
            "      Successfully uninstalled flatbuffers-23.1.21\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.0\n",
            "    Uninstalling numpy-1.21.0:\n",
            "      Successfully uninstalled numpy-1.21.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "open-clip-torch 2.15.0 requires protobuf==3.20.*, but you have protobuf 3.19.6 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "fawkes 1.0.4 requires keras==2.4.3, but you have keras 2.8.0 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "clip-retrieval 2.36.1 requires h5py<4,>=3.1.0, but you have h5py 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 numpy-1.19.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.4.3\n",
            "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from keras==2.4.3) (1.7.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras==2.4.3) (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras==2.4.3) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras==2.4.3) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from h5py->keras==2.4.3) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./fawkes/fawkes/protection.py -d ./test_imgs/ --mode low"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD60WWcT_o-x",
        "outputId": "b675bb42-e6ad-4a2b-d506-a322231d5a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identify 1 files in the directory\n",
            "Identify 1 images in the directory\n",
            "Find 2 face(s) in 22-12.jpg\n",
            "processing image 1 at 2023-02-27 04:04:54.427055\n",
            "40/40 [==============================] - 77s 2s/step\n",
            "\n",
            "\n",
            "processing image 2 at 2023-02-27 04:06:11.394479\n",
            "40/40 [==============================] - 70s 2s/step\n",
            "\n",
            "\n",
            "protection cost 147.276415 s\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lowkey"
      ],
      "metadata": {
        "id": "p8dZ21wHFXU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip supp\\ material.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UatkxgvQAQnP",
        "outputId": "8710d0b5-3e70-4854-9fae-0cdd572f91d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  supp material.zip\n",
            "   creating: supp material/\n",
            "replace __MACOSX/._supp material? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._supp material  \n",
            "  inflating: supp material/.DS_Store  \n",
            "replace __MACOSX/supp material/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/._.DS_Store  \n",
            "  inflating: supp material/requirements.txt  \n",
            "replace __MACOSX/supp material/._requirements.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/._requirements.txt  \n",
            "   creating: supp material/util/\n",
            "replace __MACOSX/supp material/._util? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/._util  \n",
            "  inflating: supp material/attack_dir_warp.py  \n",
            "replace __MACOSX/supp material/._attack_dir_warp.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/._attack_dir_warp.py  \n",
            "   creating: supp material/align/\n",
            "replace __MACOSX/supp material/._align? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/._align  \n",
            "   creating: supp material/backbone/\n",
            "replace __MACOSX/supp material/._backbone? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/._backbone  \n",
            "  inflating: supp material/util/feature_extraction_utils.py  \n",
            "replace __MACOSX/supp material/util/._feature_extraction_utils.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/util/._feature_extraction_utils.py  \n",
            "  inflating: supp material/util/__init__.py  \n",
            "replace __MACOSX/supp material/util/.___init__.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/util/.___init__.py  \n",
            "  inflating: supp material/util/attack_utils.py  \n",
            "replace __MACOSX/supp material/util/._attack_utils.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/util/._attack_utils.py  \n",
            "  inflating: supp material/util/prepare_utils.py  \n",
            "replace __MACOSX/supp material/util/._prepare_utils.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/util/._prepare_utils.py  \n",
            "  inflating: supp material/align/detector.py  \n",
            "replace __MACOSX/supp material/align/._detector.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._detector.py  \n",
            "  inflating: supp material/align/pnet.npy  \n",
            "replace __MACOSX/supp material/align/._pnet.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._pnet.npy  \n",
            "  inflating: supp material/align/rnet.npy  \n",
            "replace __MACOSX/supp material/align/._rnet.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._rnet.npy  \n",
            "  inflating: supp material/align/align_trans.py  \n",
            "replace __MACOSX/supp material/align/._align_trans.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._align_trans.py  \n",
            "  inflating: supp material/align/matlab_cp2tform.py  \n",
            "replace __MACOSX/supp material/align/._matlab_cp2tform.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._matlab_cp2tform.py  \n",
            "  inflating: supp material/align/__init__.py  \n",
            "replace __MACOSX/supp material/align/.___init__.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/.___init__.py  \n",
            "  inflating: supp material/align/get_nets.py  \n",
            "replace __MACOSX/supp material/align/._get_nets.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._get_nets.py  \n",
            "  inflating: supp material/align/box_utils.py  \n",
            "replace __MACOSX/supp material/align/._box_utils.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._box_utils.py  \n",
            "  inflating: supp material/align/onet.npy  \n",
            "replace __MACOSX/supp material/align/._onet.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._onet.npy  \n",
            "  inflating: supp material/align/first_stage.py  \n",
            "replace __MACOSX/supp material/align/._first_stage.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/align/._first_stage.py  \n",
            "  inflating: supp material/backbone/models2.py  \n",
            "replace __MACOSX/supp material/backbone/._models2.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/backbone/._models2.py  \n",
            "  inflating: supp material/backbone/model_irse.py  \n",
            "replace __MACOSX/supp material/backbone/._model_irse.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/backbone/._model_irse.py  \n",
            "  inflating: supp material/backbone/__init__.py  \n",
            "replace __MACOSX/supp material/backbone/.___init__.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/backbone/.___init__.py  \n",
            "  inflating: supp material/backbone/model_resnet.py  \n",
            "replace __MACOSX/supp material/backbone/._model_resnet.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/supp material/backbone/._model_resnet.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./supp\\ material/attack_dir_warp.py ./test_imgs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3ZxYbYlFayS",
        "outputId": "bcdb9618-47a8-4419-e1ef-4db5d95d4c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"./supp material/attack_dir_warp.py\", line 7, in <module>\n",
            "    from util.attack_utils import  Attack\n",
            "  File \"/content/supp material/util/attack_utils.py\", line 15, in <module>\n",
            "    from util.prepare_utils import get_ensemble, extract_features\n",
            "  File \"/content/supp material/util/prepare_utils.py\", line 19, in <module>\n",
            "    from lpips_pytorch import LPIPS, lpips\n",
            "ModuleNotFoundError: No module named 'lpips_pytorch'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ./supp\\ material/requirements.txt"
      ],
      "metadata": {
        "id": "1wLkA5qMHcg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/S-aiueo32/lpips-pytorch.git"
      ],
      "metadata": {
        "id": "d_DFUnMZJUXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/S-aiueo32/lpips-pytorch.git"
      ],
      "metadata": {
        "id": "sanW0cxnJc-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./supp\\ material/lowkey_attack.py --dir ./test_imgs"
      ],
      "metadata": {
        "id": "Y5fszEkCFa4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.7.0"
      ],
      "metadata": {
        "id": "F74LIJiZI0e7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "8890164936ba431effa62f548d2e190a63033d8c51925a70e93a060bef4e9d5d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}